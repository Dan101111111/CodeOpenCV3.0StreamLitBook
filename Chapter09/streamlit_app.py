"""
Cap√≠tulo 9 - Bag of Words
Demostraci√≥n del c√≥digo create_features.py
"""

import streamlit as st
import cv2
import numpy as np
import os
from PIL import Image

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="Cap√≠tulo 9 - Bag of Words", layout="wide")

# T√≠tulo
st.title("üß† Cap√≠tulo 9: Bag of Words")

def cv2_to_pil(cv2_img):
    """Convierte imagen de OpenCV (BGR) a PIL (RGB)"""
    rgb_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(rgb_img)

def pil_to_cv2(pil_img):
    """Convierte imagen de PIL (RGB) a OpenCV (BGR)"""
    rgb_array = np.array(pil_img)
    return cv2.cvtColor(rgb_array, cv2.COLOR_RGB2BGR)

class SIFTFeatureExtractor:
    """Extractor de caracter√≠sticas SIFT simplificado"""
    
    def __init__(self):
        self.sift = cv2.SIFT_create()
    
    def extract_features(self, img):
        """Extraer caracter√≠sticas SIFT de la imagen"""
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        keypoints, descriptors = self.sift.detectAndCompute(gray, None)
        
        # Dibujar keypoints
        img_with_keypoints = cv2.drawKeypoints(
            img, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
        )
        
        return {
            'keypoints': keypoints,
            'descriptors': descriptors,
            'img_with_keypoints': img_with_keypoints,
            'num_features': len(keypoints) if keypoints else 0
        }

def create_bovw_features(descriptors_list, k=50):
    """Crear Bag of Visual Words usando K-means"""
    if not descriptors_list or len(descriptors_list) == 0:
        return None, None
    
    try:
        from sklearn.cluster import KMeans
        
        # Concatenar todos los descriptores
        all_descriptors = np.vstack(descriptors_list)
        
        # Ajustar k si es mayor que el n√∫mero de muestras disponibles
        n_samples = all_descriptors.shape[0]
        original_k = k
        if k > n_samples:
            k = max(1, min(n_samples, 10))  # Usar m√°ximo 10 clusters o el n√∫mero de muestras
            st.warning(f"‚ö†Ô∏è Ajustando n√∫mero de clusters de {original_k} original a {k} debido a pocas muestras ({n_samples})")
        
        # Aplicar K-means para crear vocabulario visual
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
        kmeans.fit(all_descriptors)
        
        # Crear histograma para cada imagen
        bovw_features = []
        for descriptors in descriptors_list:
            if descriptors is not None:
                # Predecir clusters para cada descriptor
                labels = kmeans.predict(descriptors)
                # Crear histograma
                hist, _ = np.histogram(labels, bins=k, range=(0, k))
                # Normalizar
                hist = hist.astype(float)
                if np.sum(hist) > 0:
                    hist = hist / np.sum(hist)
                bovw_features.append(hist)
            else:
                bovw_features.append(np.zeros(k))
        
        return kmeans, bovw_features
        
    except ImportError:
        st.error("‚ùå scikit-learn no est√° instalado. Usando m√©todo alternativo.")
        return None, None

def load_example_images():
    """Carga m√∫ltiples im√°genes de ejemplo con m√°s caracter√≠sticas"""
    images = []
    
    # Crear diferentes im√°genes de ejemplo con m√°s detalles para generar m√°s caracter√≠sticas SIFT
    for i in range(5):  # Aumentamos a 5 im√°genes
        img = np.ones((400, 500, 3), dtype=np.uint8) * (30 + i * 20)
        
        if i == 0:  # Imagen con m√∫ltiples c√≠rculos
            colors = [(0, 255, 0), (255, 0, 0), (0, 0, 255), (255, 255, 0)]
            positions = [(80, 80), (300, 120), (150, 250), (400, 300)]
            for pos, color in zip(positions, colors):
                cv2.circle(img, pos, 25, color, -1)
                cv2.circle(img, pos, 35, (255, 255, 255), 2)
                
        elif i == 1:  # Imagen con rect√°ngulos y l√≠neas
            cv2.rectangle(img, (50, 50), (150, 150), (0, 0, 255), -1)
            cv2.rectangle(img, (200, 180), (350, 280), (255, 255, 0), -1)
            cv2.line(img, (0, 200), (500, 200), (255, 0, 255), 3)
            cv2.line(img, (250, 0), (250, 400), (0, 255, 255), 3)
            
        elif i == 2:  # Imagen con formas mixtas
            cv2.circle(img, (150, 150), 60, (255, 0, 255), -1)
            cv2.rectangle(img, (50, 250), (200, 350), (0, 255, 255), -1)
            cv2.ellipse(img, (350, 200), (80, 40), 45, 0, 360, (255, 100, 100), -1)
            
        elif i == 3:  # Imagen con patr√≥n de puntos
            for x in range(50, 450, 60):
                for y in range(50, 350, 60):
                    color = (np.random.randint(100, 255), np.random.randint(100, 255), np.random.randint(100, 255))
                    cv2.circle(img, (x, y), 15, color, -1)
                    
        else:  # Imagen con texto y formas
            cv2.putText(img, "SIFT", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (255, 255, 255), 3)
            cv2.putText(img, "TEST", (250, 300), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)
            cv2.rectangle(img, (300, 50), (480, 150), (255, 0, 0), 3)
        
        images.append(img)
    
    return images

# Sidebar para configuraci√≥n
st.sidebar.header("üõ†Ô∏è Configuraci√≥n")

use_multiple_images = st.sidebar.checkbox("Usar m√∫ltiples im√°genes", value=True)

if not use_multiple_images:
    image_source = st.sidebar.radio(
        "Selecciona imagen:",
        ["üñºÔ∏è Imagen de ejemplo", "üì§ Cargar imagen"]
    )

k_clusters = st.sidebar.slider("N√∫mero de clusters (K)", 5, 50, 20)

# Cargar im√°genes
images = []
image_names = []

if use_multiple_images:
    # Usar m√∫ltiples im√°genes de ejemplo
    images = load_example_images()
    image_names = ["c√≠rculos.jpg", "geometr√≠a.jpg", "formas.jpg", "puntos.jpg", "texto.jpg"]
    st.sidebar.success(f"‚úÖ Usando {len(images)} im√°genes de ejemplo")
else:
    # Usar una sola imagen
    if image_source == "üì§ Cargar imagen":
        uploaded_file = st.sidebar.file_uploader(
            "Sube tu imagen:",
            type=['png', 'jpg', 'jpeg', 'bmp']
        )
        
        if uploaded_file is not None:
            try:
                pil_image = Image.open(uploaded_file)
                img = pil_to_cv2(pil_image)
                images = [img]
                image_names = [uploaded_file.name]
                st.sidebar.success(f"‚úÖ Imagen cargada: {uploaded_file.name}")
            except Exception as e:
                st.sidebar.error(f"‚ùå Error: {str(e)}")
        else:
            st.sidebar.info("üëÜ Sube una imagen")
    else:
        images = load_example_images()[:1]  # Solo la primera
        image_names = ["ejemplo.jpg"]
        st.sidebar.success("‚úÖ Usando imagen de ejemplo")

# Mostrar informaci√≥n
if images:
    st.sidebar.markdown("---")
    st.sidebar.markdown("**üìä Info del Dataset:**")
    st.sidebar.write(f"‚Ä¢ **N√∫mero de im√°genes:** {len(images)}")
    st.sidebar.write(f"‚Ä¢ **Clusters K-means:** {k_clusters}")

if images:
    # Procesar im√°genes
    try:
        with st.spinner("üîÑ Extrayendo caracter√≠sticas SIFT..."):
            extractor = SIFTFeatureExtractor()
            results = []
            descriptors_list = []
            
            for img in images:
                result = extractor.extract_features(img)
                results.append(result)
                if result['descriptors'] is not None:
                    descriptors_list.append(result['descriptors'])
        
        # Verificar que tenemos suficientes caracter√≠sticas
        if not descriptors_list:
            st.error("‚ùå No se encontraron caracter√≠sticas SIFT en las im√°genes.")
            st.stop()
        
        total_descriptors = sum(len(desc) for desc in descriptors_list)
        st.info(f"‚ÑπÔ∏è Total de descriptores SIFT encontrados: {total_descriptors}")
        
        with st.spinner("üîÑ Creando Bag of Visual Words..."):
            kmeans_model, bovw_features = create_bovw_features(descriptors_list, k_clusters)
        
        st.success("‚úÖ **Bag of Visual Words creado**")
        
        # M√©tricas
        cols = st.columns(4)
        with cols[0]:
            st.metric("Im√°genes", len(images))
        with cols[1]:
            total_features = sum(r['num_features'] for r in results)
            st.metric("Caracter√≠sticas SIFT", total_features)
        with cols[2]:
            st.metric("Vocabulario Visual", f"{k_clusters} palabras")
        with cols[3]:
            bovw_status = "‚úÖ" if bovw_features else "‚ùå"
            st.metric("BoVW", bovw_status)
            
    except Exception as e:
        st.error(f"‚ùå Error: {str(e)}")
        st.stop()
    
    # Mostrar c√≥digo
    st.subheader("üìÑ C√≥digo Principal:")
    st.code("""
# Bag of Visual Words - C√≥digo principal
sift = cv2.SIFT_create()
keypoints, descriptors = sift.detectAndCompute(gray, None)

# Crear vocabulario visual con K-means
from sklearn.cluster import KMeans
all_descriptors = np.vstack(descriptors_list)
kmeans = KMeans(n_clusters=k)
kmeans.fit(all_descriptors)

# Crear histograma BoVW para cada imagen
labels = kmeans.predict(descriptors)
hist, _ = np.histogram(labels, bins=k)
""", language="python")
    
    # Resultados
    st.subheader("üñºÔ∏è Caracter√≠sticas Extra√≠das:")
    
    # Mostrar im√°genes con keypoints
    cols = st.columns(min(len(images), 3))
    for i, (img, result, name) in enumerate(zip(images, results, image_names)):
        with cols[i % 3]:
            st.markdown(f"**{name}**")
            st.image(cv2_to_pil(result['img_with_keypoints']), use_container_width=True)
            st.write(f"Caracter√≠sticas: {result['num_features']}")
    
    # Mostrar histogramas BoVW si est√°n disponibles
    if bovw_features:
        st.subheader("üìä Histogramas Bag of Visual Words:")
        
        for i, (hist, name) in enumerate(zip(bovw_features, image_names)):
            st.markdown(f"**Histograma BoVW - {name}:**")
            st.bar_chart(hist)
    
    # Explicaci√≥n
    st.subheader("üìö Explicaci√≥n:")
    st.markdown("""
    **Bag of Visual Words (BoVW)** es una t√©cnica de representaci√≥n de im√°genes:
    
    1. **Extracci√≥n SIFT**: Detecta puntos clave y calcula descriptores locales
    2. **Vocabulario Visual**: Usa K-means para agrupar descriptores similares
    3. **Cuantizaci√≥n**: Asigna cada descriptor al cluster m√°s cercano
    4. **Histograma**: Cuenta frecuencia de cada "palabra visual" por imagen
    5. **Clasificaci√≥n**: Los histogramas se usan como features para ML
    """)

else:
    st.error("‚ùå No se pudieron cargar im√°genes")