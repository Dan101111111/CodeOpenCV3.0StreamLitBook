"""
Cap√≠tulo 10 - Estimaci√≥n de Pose
Demostraci√≥n del c√≥digo pose_estimation.py
"""

import streamlit as st
import cv2
import numpy as np
import os
from PIL import Image

# Configuraci√≥n de la p√°gina
st.set_page_config(page_title="Cap√≠tulo 10 - Pose Estimation", layout="wide")

# T√≠tulo
st.title("üìç Cap√≠tulo 10: Estimaci√≥n de Pose")

def cv2_to_pil(cv2_img):
    """Convierte imagen de OpenCV (BGR) a PIL (RGB)"""
    rgb_img = cv2.cvtColor(cv2_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(rgb_img)

def pil_to_cv2(pil_img):
    """Convierte imagen de PIL (RGB) a OpenCV (BGR)"""
    rgb_array = np.array(pil_img)
    return cv2.cvtColor(rgb_array, cv2.COLOR_RGB2BGR)

def estimate_pose_simple(img):
    """Estimaci√≥n de pose simplificada usando caracter√≠sticas"""
    # Convertir a escala de grises
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Detectar caracter√≠sticas usando SIFT
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(gray, None)
    
    # Dibujar keypoints
    img_with_keypoints = cv2.drawKeypoints(
        img, keypoints, None, 
        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS
    )
    
    # Simulaci√≥n de pose estimation con puntos 3D ficticios
    # En una aplicaci√≥n real, estos ser√≠an puntos conocidos del objeto 3D
    object_3d_points = np.array([
        [0, 0, 0],      # Origen
        [1, 0, 0],      # Eje X
        [0, 1, 0],      # Eje Y
        [0, 0, -1],     # Eje Z
        [1, 1, 0],      # Esquina
        [1, 0, -1],     # Esquina
        [0, 1, -1],     # Esquina
        [1, 1, -1]      # Esquina
    ], dtype=np.float32)
    
    # Par√°metros de c√°mara simulados
    # En una aplicaci√≥n real, estos se obtendr√≠an de la calibraci√≥n
    camera_matrix = np.array([
        [800, 0, img.shape[1]/2],
        [0, 800, img.shape[0]/2],
        [0, 0, 1]
    ], dtype=np.float32)
    
    dist_coeffs = np.zeros((4, 1))
    
    # Si tenemos suficientes keypoints, simular correspondencias
    if len(keypoints) >= 4:
        # Tomar los primeros 8 keypoints como correspondencias simuladas
        image_points = np.array([
            [kp.pt[0], kp.pt[1]] for kp in keypoints[:8]
        ], dtype=np.float32)
        
        # Si tenemos menos de 8 keypoints, usar solo los disponibles
        num_points = min(len(keypoints), 8)
        image_points = image_points[:num_points]
        object_points_used = object_3d_points[:num_points]
        
        try:
            # Resolver PnP para estimar pose
            success, rvec, tvec = cv2.solvePnP(
                object_points_used, image_points, 
                camera_matrix, dist_coeffs
            )
            
            if success:
                # Proyectar ejes 3D a la imagen
                axis_3d = np.array([
                    [0, 0, 0],    # Origen
                    [3, 0, 0],    # Eje X (rojo)
                    [0, 3, 0],    # Eje Y (verde)
                    [0, 0, -3]    # Eje Z (azul)
                ], dtype=np.float32)
                
                axis_2d, _ = cv2.projectPoints(
                    axis_3d, rvec, tvec, camera_matrix, dist_coeffs
                )
                
                # Dibujar ejes en la imagen
                img_with_pose = img.copy()
                origin = tuple(map(int, axis_2d[0].ravel()))
                x_axis = tuple(map(int, axis_2d[1].ravel()))
                y_axis = tuple(map(int, axis_2d[2].ravel()))
                z_axis = tuple(map(int, axis_2d[3].ravel()))
                
                # Dibujar l√≠neas de los ejes
                cv2.arrowedLine(img_with_pose, origin, x_axis, (0, 0, 255), 3)  # X - Rojo
                cv2.arrowedLine(img_with_pose, origin, y_axis, (0, 255, 0), 3)  # Y - Verde  
                cv2.arrowedLine(img_with_pose, origin, z_axis, (255, 0, 0), 3)  # Z - Azul
                
                return {
                    'success': True,
                    'keypoints': keypoints,
                    'img_with_keypoints': img_with_keypoints,
                    'img_with_pose': img_with_pose,
                    'rvec': rvec,
                    'tvec': tvec,
                    'num_features': len(keypoints)
                }
                
        except cv2.error:
            pass
    
    # Si no se puede estimar pose, devolver solo keypoints
    return {
        'success': False,
        'keypoints': keypoints,
        'img_with_keypoints': img_with_keypoints,
        'img_with_pose': img,
        'num_features': len(keypoints)
    }

def load_example_image():
    """Carga imagen de ejemplo"""
    # Crear imagen de ejemplo con patrones geom√©tricos
    img = np.ones((400, 600, 3), dtype=np.uint8) * 200
    
    # Dibujar un patr√≥n similar a un tablero de ajedrez simplificado
    for i in range(0, 400, 50):
        for j in range(0, 600, 50):
            if (i//50 + j//50) % 2 == 0:
                cv2.rectangle(img, (j, i), (j+50, i+50), (0, 0, 0), -1)
    
    # A√±adir algunos c√≠rculos para m√°s caracter√≠sticas
    cv2.circle(img, (150, 150), 20, (255, 0, 0), -1)
    cv2.circle(img, (450, 150), 20, (0, 255, 0), -1)
    cv2.circle(img, (300, 300), 20, (0, 0, 255), -1)
    
    return img

# Sidebar para configuraci√≥n
st.sidebar.header("üõ†Ô∏è Configuraci√≥n")

image_source = st.sidebar.radio(
    "Selecciona imagen:",
    ["üñºÔ∏è Imagen de ejemplo", "üì§ Cargar imagen"]
)

# Cargar imagen
img = None
img_name = ""

if image_source == "üì§ Cargar imagen":
    uploaded_file = st.sidebar.file_uploader(
        "Sube tu imagen:",
        type=['png', 'jpg', 'jpeg', 'bmp']
    )
    
    if uploaded_file is not None:
        try:
            pil_image = Image.open(uploaded_file)
            img = pil_to_cv2(pil_image)
            img_name = uploaded_file.name
            st.sidebar.success(f"‚úÖ Imagen cargada: {img_name}")
        except Exception as e:
            st.sidebar.error(f"‚ùå Error: {str(e)}")
    else:
        st.sidebar.info("üëÜ Sube una imagen")
else:
    img = load_example_image()
    img_name = "patron_ejemplo.jpg"
    st.sidebar.success(f"‚úÖ Usando: {img_name}")

# Mostrar informaci√≥n de la imagen
if img is not None:
    height, width = img.shape[:2]
    st.sidebar.markdown("---")
    st.sidebar.markdown("**üìä Info de la Imagen:**")
    st.sidebar.write(f"‚Ä¢ **Dimensiones:** {width} x {height}")

if img is not None:
    # Procesar imagen
    try:
        with st.spinner("üîÑ Procesando estimaci√≥n de pose..."):
            results = estimate_pose_simple(img)
        
        if results['success']:
            st.success("‚úÖ **Pose estimada correctamente**")
        else:
            st.warning("‚ö†Ô∏è **Pose parcial** - Solo caracter√≠sticas detectadas")
        
        # M√©tricas
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Imagen Original", f"{img.shape[1]}x{img.shape[0]}")
        with col2:
            st.metric("Caracter√≠sticas SIFT", results['num_features'])
        with col3:
            pose_status = "‚úÖ" if results['success'] else "‚ö†Ô∏è"
            st.metric("Estimaci√≥n Pose", pose_status)
            
    except Exception as e:
        st.error(f"‚ùå Error: {str(e)}")
        st.stop()
    
    # Mostrar c√≥digo
    st.subheader("üìÑ C√≥digo Principal:")
    st.code("""
# Pose Estimation - C√≥digo principal
sift = cv2.SIFT_create()
keypoints, descriptors = sift.detectAndCompute(gray, None)

# Puntos 3D del objeto (conocidos)
object_points = np.array([[0,0,0], [1,0,0], [0,1,0], [0,0,-1]], dtype=np.float32)
# Puntos 2D correspondientes en la imagen
image_points = np.array([[kp.pt[0], kp.pt[1]] for kp in keypoints[:4]], dtype=np.float32)

# Resolver PnP para obtener pose
success, rvec, tvec = cv2.solvePnP(object_points, image_points, camera_matrix, dist_coeffs)
""", language="python")
    
    # Resultados
    st.subheader("üñºÔ∏è Resultados:")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Imagen Original**")
        st.image(cv2_to_pil(img), use_container_width=True)
        
        st.markdown("**Caracter√≠sticas SIFT**")
        st.image(cv2_to_pil(results['img_with_keypoints']), use_container_width=True)
    
    with col2:
        if results['success']:
            st.markdown("**Pose Estimada (con ejes 3D)**")
            st.image(cv2_to_pil(results['img_with_pose']), use_container_width=True)
            
            # Mostrar vectores de rotaci√≥n y traslaci√≥n
            st.markdown("**Par√°metros de Pose:**")
            st.write(f"**Vector Rotaci√≥n (rvec):** {results['rvec'].flatten()}")
            st.write(f"**Vector Traslaci√≥n (tvec):** {results['tvec'].flatten()}")
        else:
            st.markdown("**Sin Estimaci√≥n de Pose**")
            st.image(cv2_to_pil(results['img_with_pose']), use_container_width=True)
            st.info("üí° Se necesitan al menos 4 correspondencias confiables para estimar pose")
    
    # Explicaci√≥n
    st.subheader("üìö Explicaci√≥n:")
    st.markdown("""
    **Pose Estimation** determina la posici√≥n y orientaci√≥n de un objeto en 3D:
    
    1. **Detecci√≥n de Caracter√≠sticas**: Usa SIFT para encontrar puntos clave
    2. **Correspondencias**: Relaciona puntos 2D de la imagen con puntos 3D del objeto
    3. **Problema PnP**: Resuelve Perspective-n-Point usando cv2.solvePnP
    4. **Par√°metros de Pose**: Obtiene vectores de rotaci√≥n (rvec) y traslaci√≥n (tvec)
    5. **Visualizaci√≥n**: Proyecta ejes 3D a la imagen para mostrar la pose
    """)

else:
    st.error("‚ùå No se pudo cargar la imagen")