"""
Aplicaci√≥n Streamlit - Detecci√≥n Facial y Caracter√≠sticas Interactiva
Aplicaci√≥n educativa para explorar detecci√≥n de rostros, ojos, nariz, boca y orejas
"""

import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import os

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Detecci√≥n Facial Interactiva",
    page_icon="üë§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("üë§ Detecci√≥n Facial y Caracter√≠sticas Interactiva")
st.markdown("**Explora diferentes tipos de detecci√≥n facial usando Haar Cascades**")

# Funciones auxiliares
@st.cache_resource
def load_cascade_classifiers():
    """Carga todos los clasificadores Haar Cascade disponibles"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    cascade_dir = os.path.join(script_dir, 'cascade_files')
    
    classifiers = {}
    cascade_files = {
        'face': 'haarcascade_frontalface_alt.xml',
        'eye': 'haarcascade_eye.xml',
        'nose': 'haarcascade_mcs_nose.xml',
        'mouth': 'haarcascade_mcs_mouth.xml',
        'left_ear': 'haarcascade_mcs_leftear.xml',
        'right_ear': 'haarcascade_mcs_rightear.xml'
    }
    
    for feature, filename in cascade_files.items():
        cascade_path = os.path.join(cascade_dir, filename)
        if os.path.exists(cascade_path):
            classifiers[feature] = cv2.CascadeClassifier(cascade_path)
        else:
            # Fallback a clasificador frontal por defecto
            classifiers[feature] = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    
    return classifiers

@st.cache_resource
def load_overlay_images():
    """Carga las im√°genes de overlay (m√°scaras, gafas, etc.)"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    images_dir = os.path.join(script_dir, 'images')
    
    overlays = {}
    overlay_files = {
        'sunglasses': 'sunglasses.png',
        'moustache': 'moustache.png',
        'mask': 'mask_hannibal.png'
    }
    
    for name, filename in overlay_files.items():
        overlay_path = os.path.join(images_dir, filename)
        if os.path.exists(overlay_path):
            img = cv2.imread(overlay_path, cv2.IMREAD_UNCHANGED)
            if img is not None:
                overlays[name] = img
    
    return overlays

@st.cache_data
def create_sample_face_image():
    """Crea una imagen de ejemplo con caras sint√©ticas"""
    img = np.ones((600, 800, 3), dtype=np.uint8) * 240
    
    # Simular caras con formas geom√©tricas
    # Cara 1
    cv2.ellipse(img, (200, 200), (80, 100), 0, 0, 360, (220, 200, 180), -1)  # Cara
    cv2.ellipse(img, (180, 180), (15, 20), 0, 0, 360, (50, 50, 50), -1)      # Ojo izq
    cv2.ellipse(img, (220, 180), (15, 20), 0, 0, 360, (50, 50, 50), -1)      # Ojo der
    cv2.ellipse(img, (200, 200), (8, 12), 0, 0, 360, (100, 80, 70), -1)      # Nariz
    cv2.ellipse(img, (200, 230), (20, 10), 0, 0, 360, (150, 100, 100), -1)   # Boca
    
    # Cara 2
    cv2.ellipse(img, (600, 200), (70, 90), 0, 0, 360, (210, 190, 170), -1)   # Cara
    cv2.ellipse(img, (585, 180), (12, 18), 0, 0, 360, (40, 40, 40), -1)      # Ojo izq
    cv2.ellipse(img, (615, 180), (12, 18), 0, 0, 360, (40, 40, 40), -1)      # Ojo der
    cv2.ellipse(img, (600, 200), (6, 10), 0, 0, 360, (90, 70, 60), -1)       # Nariz
    cv2.ellipse(img, (600, 225), (18, 8), 0, 0, 360, (140, 90, 90), -1)      # Boca
    
    # Cara 3 (perfil)
    cv2.ellipse(img, (400, 400), (60, 80), 15, 0, 180, (200, 180, 160), -1)  # Media cara
    cv2.ellipse(img, (420, 380), (10, 15), 0, 0, 360, (30, 30, 30), -1)      # Ojo
    cv2.ellipse(img, (435, 400), (5, 8), 0, 0, 360, (80, 60, 50), -1)        # Nariz
    cv2.ellipse(img, (425, 420), (12, 6), 0, 0, 360, (130, 80, 80), -1)      # Boca
    
    # Agregar texto
    cv2.putText(img, 'DETECCION FACIAL', (250, 500), 
               cv2.FONT_HERSHEY_SIMPLEX, 1.2, (50, 50, 50), 2)
    cv2.putText(img, 'Caras de Ejemplo', (290, 530), 
               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 100, 100), 1)
    
    return img

def pil_to_cv2(pil_image):
    """Convierte imagen PIL a formato OpenCV"""
    open_cv_image = np.array(pil_image.convert('RGB'))
    return cv2.cvtColor(open_cv_image, cv2.COLOR_RGB2BGR)

def cv2_to_pil(cv2_image):
    """Convierte imagen OpenCV a formato PIL"""
    rgb_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)
    return Image.fromarray(rgb_image)

def detect_features(image, classifiers, detection_type, scale_factor=1.1, 
                   min_neighbors=3, min_size=(30, 30), max_size=()):
    """
    Detecta caracter√≠sticas faciales usando Haar Cascades
    
    Args:
        image: Imagen de entrada
        classifiers: Diccionario de clasificadores
        detection_type: Tipo de detecci√≥n ('face', 'eye', 'nose', etc.)
        scale_factor: Factor de escala para detecci√≥n
        min_neighbors: M√≠nimo n√∫mero de vecinos
        min_size: Tama√±o m√≠nimo de detecci√≥n
        max_size: Tama√±o m√°ximo de detecci√≥n
    
    Returns:
        Lista de rect√°ngulos detectados
    """
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    if detection_type in classifiers:
        classifier = classifiers[detection_type]
        
        detections = classifier.detectMultiScale(
            gray,
            scaleFactor=scale_factor,
            minNeighbors=min_neighbors,
            minSize=min_size,
            maxSize=max_size if max_size else ()
        )
        
        return detections
    
    return []

def draw_detections(image, detections, color=(0, 255, 0), thickness=2, 
                   detection_type='face', show_confidence=False):
    """Dibuja rect√°ngulos alrededor de las detecciones"""
    result = image.copy()
    
    colors = {
        'face': (0, 255, 0),      # Verde
        'eye': (255, 0, 0),       # Rojo
        'nose': (0, 0, 255),      # Azul
        'mouth': (255, 0, 255),   # Magenta
        'left_ear': (0, 255, 255), # Cyan
        'right_ear': (255, 255, 0) # Amarillo
    }
    
    detection_color = colors.get(detection_type, color)
    
    for i, (x, y, w, h) in enumerate(detections):
        cv2.rectangle(result, (x, y), (x + w, y + h), detection_color, thickness)
        
        # Agregar etiqueta
        label = f"{detection_type.title()} {i+1}"
        cv2.putText(result, label, (x, y - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, detection_color, 1)
    
    return result

def apply_overlay(image, detections, overlay_img, detection_type='face', 
                 scale_factor=1.0, offset_y=0):
    """Aplica overlay (gafas, bigote, etc.) sobre las detecciones"""
    if overlay_img is None or len(detections) == 0:
        return image
    
    result = image.copy()
    
    for (x, y, w, h) in detections:
        # Redimensionar overlay seg√∫n el tama√±o de la detecci√≥n
        overlay_width = int(w * scale_factor)
        overlay_height = int(overlay_img.shape[0] * (overlay_width / overlay_img.shape[1]))
        
        # Posici√≥n del overlay
        overlay_x = x + int((w - overlay_width) / 2)
        overlay_y = y + offset_y
        
        # Redimensionar overlay
        overlay_resized = cv2.resize(overlay_img, (overlay_width, overlay_height))
        
        # Verificar l√≠mites
        if (overlay_x >= 0 and overlay_y >= 0 and 
            overlay_x + overlay_width <= result.shape[1] and 
            overlay_y + overlay_height <= result.shape[0]):
            
            # Aplicar overlay con canal alpha si est√° disponible
            if overlay_resized.shape[2] == 4:  # Con canal alpha
                alpha = overlay_resized[:, :, 3] / 255.0
                for c in range(3):
                    result[overlay_y:overlay_y + overlay_height, 
                          overlay_x:overlay_x + overlay_width, c] = \
                        alpha * overlay_resized[:, :, c] + \
                        (1 - alpha) * result[overlay_y:overlay_y + overlay_height, 
                                           overlay_x:overlay_x + overlay_width, c]
            else:  # Sin canal alpha
                result[overlay_y:overlay_y + overlay_height, 
                      overlay_x:overlay_x + overlay_width] = overlay_resized
    
    return result

def detect_multiple_features(image, classifiers, selected_features, 
                           scale_factor, min_neighbors, min_size):
    """Detecta m√∫ltiples caracter√≠sticas en una sola pasada"""
    result = image.copy()
    all_detections = {}
    
    for feature in selected_features:
        detections = detect_features(image, classifiers, feature, 
                                   scale_factor, min_neighbors, min_size)
        all_detections[feature] = detections
        result = draw_detections(result, detections, detection_type=feature)
    
    return result, all_detections

# Cargar recursos
classifiers = load_cascade_classifiers()
overlays = load_overlay_images()

# Sidebar - Controles
st.sidebar.header("‚öôÔ∏è Controles")

# Upload de imagen
uploaded_file = st.sidebar.file_uploader(
    "üìÅ Sube tu imagen", 
    type=['png', 'jpg', 'jpeg'],
    help="Formatos soportados: PNG, JPG, JPEG"
)

# Cargar imagen
if uploaded_file is not None:
    pil_image = Image.open(uploaded_file)
    image = pil_to_cv2(pil_image)
    image_source = f"üìÅ {uploaded_file.name}"
else:
    image = create_sample_face_image()
    image_source = "üñºÔ∏è Imagen de ejemplo generada"

# Informaci√≥n de la imagen
h, w = image.shape[:2]
st.sidebar.info(f"**Imagen actual:** {image_source}")
st.sidebar.info(f"**Dimensiones:** {w} x {h} p√≠xeles")

st.sidebar.markdown("---")

# Men√∫ de detecci√≥n
st.sidebar.subheader("üîç Tipo de Detecci√≥n")

detection_mode = st.sidebar.selectbox(
    "Modo de detecci√≥n:",
    options=['single', 'multiple', 'overlay_mode'],
    format_func=lambda x: {
        'single': 'üéØ Detecci√≥n Individual',
        'multiple': 'üë• Detecci√≥n M√∫ltiple',
        'overlay_mode': 'üé≠ Modo Overlay'
    }[x],
    help="Selecciona el modo de detecci√≥n"
)

if detection_mode == 'single':
    detection_type = st.sidebar.selectbox(
        "Caracter√≠stica a detectar:",
        options=['face', 'eye', 'nose', 'mouth', 'left_ear', 'right_ear'],
        format_func=lambda x: {
            'face': 'üë§ Rostro',
            'eye': 'üëÅÔ∏è Ojos',
            'nose': 'üëÉ Nariz',
            'mouth': 'üëÑ Boca',
            'left_ear': 'üëÇ Oreja Izquierda',
            'right_ear': 'üëÇ Oreja Derecha'
        }[x]
    )
elif detection_mode == 'multiple':
    selected_features = st.sidebar.multiselect(
        "Caracter√≠sticas a detectar:",
        options=['face', 'eye', 'nose', 'mouth', 'left_ear', 'right_ear'],
        default=['face', 'eye'],
        format_func=lambda x: {
            'face': 'üë§ Rostro',
            'eye': 'üëÅÔ∏è Ojos',
            'nose': 'üëÉ Nariz',
            'mouth': 'üëÑ Boca',
            'left_ear': 'üëÇ Oreja Izquierda',
            'right_ear': 'üëÇ Oreja Derecha'
        }[x]
    )
else:  # overlay_mode
    overlay_type = st.sidebar.selectbox(
        "Tipo de overlay:",
        options=['sunglasses', 'moustache', 'mask'],
        format_func=lambda x: {
            'sunglasses': 'üï∂Ô∏è Gafas de Sol',
            'moustache': 'ü•∏ Bigote',
            'mask': 'üé≠ M√°scara'
        }[x]
    )

st.sidebar.markdown("---")

# Par√°metros de detecci√≥n
st.sidebar.subheader("üéõÔ∏è Par√°metros de Detecci√≥n")

scale_factor = st.sidebar.slider(
    "Factor de escala:", 
    1.01, 2.0, 1.1, 0.01,
    help="Qu√© tan r√°pido se reduce el tama√±o de imagen en cada escala"
)

min_neighbors = st.sidebar.slider(
    "M√≠nimos vecinos:", 
    1, 10, 3, 1,
    help="Cu√°ntos vecinos debe tener cada rect√°ngulo candidato para ser v√°lido"
)

min_size = st.sidebar.slider(
    "Tama√±o m√≠nimo:", 
    10, 200, 30, 5,
    help="Tama√±o m√≠nimo de la caracter√≠stica a detectar (p√≠xeles)"
)

max_size = st.sidebar.slider(
    "Tama√±o m√°ximo:", 
    50, 500, 300, 10,
    help="Tama√±o m√°ximo de la caracter√≠stica a detectar (0 = sin l√≠mite)"
)

if detection_mode == 'overlay_mode':
    st.sidebar.subheader("üé® Par√°metros de Overlay")
    
    overlay_scale = st.sidebar.slider(
        "Escala del overlay:", 
        0.5, 2.0, 1.0, 0.1,
        help="Escala del elemento overlay respecto a la detecci√≥n"
    )
    
    overlay_offset_y = st.sidebar.slider(
        "Desplazamiento Y:", 
        -100, 100, 0, 5,
        help="Desplazamiento vertical del overlay"
    )

# Opciones de visualizaci√≥n
st.sidebar.markdown("---")
st.sidebar.subheader("üëÅÔ∏è Opciones de Vista")

show_comparison = st.sidebar.checkbox("Comparaci√≥n Lado a Lado", True)
show_statistics = st.sidebar.checkbox("Mostrar Estad√≠sticas", True)

# Procesamiento seg√∫n el modo
max_size_tuple = (max_size, max_size) if max_size > 0 else ()

if detection_mode == 'single':
    # Detecci√≥n individual
    detections = detect_features(image, classifiers, detection_type, 
                               scale_factor, min_neighbors, 
                               (min_size, min_size), max_size_tuple)
    
    processed_image = draw_detections(image, detections, detection_type=detection_type)
    
    detection_title = {
        'face': 'üë§ Detecci√≥n de Rostros',
        'eye': 'üëÅÔ∏è Detecci√≥n de Ojos',
        'nose': 'üëÉ Detecci√≥n de Nariz',
        'mouth': 'üëÑ Detecci√≥n de Boca',
        'left_ear': 'üëÇ Detecci√≥n Oreja Izquierda',
        'right_ear': 'üëÇ Detecci√≥n Oreja Derecha'
    }[detection_type]

elif detection_mode == 'multiple':
    # Detecci√≥n m√∫ltiple
    processed_image, all_detections = detect_multiple_features(
        image, classifiers, selected_features, 
        scale_factor, min_neighbors, (min_size, min_size)
    )
    
    detection_title = "üë• Detecci√≥n M√∫ltiple de Caracter√≠sticas"

else:  # overlay_mode
    # Modo overlay
    face_detections = detect_features(image, classifiers, 'face', 
                                    scale_factor, min_neighbors, 
                                    (min_size, min_size), max_size_tuple)
    
    overlay_img = overlays.get(overlay_type)
    processed_image = apply_overlay(image, face_detections, overlay_img, 
                                  'face', overlay_scale, overlay_offset_y)
    
    overlay_names = {'sunglasses': 'üï∂Ô∏è Gafas', 'moustache': 'ü•∏ Bigote', 'mask': 'üé≠ M√°scara'}
    detection_title = f"üé≠ Overlay: {overlay_names[overlay_type]}"

# √Årea principal
if show_comparison:
    st.subheader(f"{detection_title} - Comparaci√≥n")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**üñºÔ∏è Imagen Original**")
        st.image(cv2_to_pil(image), use_container_width=True)
    
    with col2:
        st.write(f"**{detection_title}**")
        st.image(cv2_to_pil(processed_image), use_container_width=True)
else:
    st.subheader(detection_title)
    st.image(cv2_to_pil(processed_image), use_container_width=True)

# Estad√≠sticas
if show_statistics and detection_mode != 'overlay_mode':
    st.subheader("üìä Estad√≠sticas de Detecci√≥n")
    
    if detection_mode == 'single':
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Detecciones Encontradas", len(detections))
        with col2:
            if len(detections) > 0:
                avg_size = np.mean([w*h for (x,y,w,h) in detections])
                st.metric("Tama√±o Promedio", f"{avg_size:.0f} px¬≤")
        with col3:
            confidence_score = len(detections) / max(1, (w*h) // 10000)
            st.metric("Puntuaci√≥n Confianza", f"{confidence_score:.2f}")
    
    elif detection_mode == 'multiple':
        cols = st.columns(len(selected_features))
        for i, feature in enumerate(selected_features):
            with cols[i]:
                count = len(all_detections.get(feature, []))
                feature_name = {
                    'face': 'Rostros', 'eye': 'Ojos', 'nose': 'Narices',
                    'mouth': 'Bocas', 'left_ear': 'Orejas Izq', 'right_ear': 'Orejas Der'
                }[feature]
                st.metric(feature_name, count)

# Bot√≥n de descarga
col1, col2, col3 = st.columns([1, 2, 1])
with col2:
    processed_pil = cv2_to_pil(processed_image)
    buf = io.BytesIO()
    processed_pil.save(buf, format='PNG')
    
    st.download_button(
        label="üì• Descargar Imagen Procesada",
        data=buf.getvalue(),
        file_name=f"face_detection_{detection_mode}.png",
        mime="image/png",
        use_container_width=True
    )

# Informaci√≥n educativa
st.sidebar.markdown("---")
st.sidebar.subheader("üìö Informaci√≥n Educativa")

with st.sidebar.expander("üîç Sobre Haar Cascades"):
    st.markdown("""
    **¬øQu√© son los Haar Cascades?**
    - Clasificadores entrenados con caracter√≠sticas Haar
    - Detectan patrones espec√≠ficos en im√°genes
    - Funcionan bien para detecci√≥n facial
    
    **Par√°metros Clave:**
    - **Scale Factor**: Velocidad de b√∫squeda multi-escala
    - **Min Neighbors**: Robustez vs sensibilidad
    - **Min/Max Size**: Rango de tama√±os a detectar
    
    **Ventajas:**
    - R√°pidos y eficientes
    - No requieren GPU
    - Funcionan bien en tiempo real
    
    **Limitaciones:**
    - Sensibles a orientaci√≥n
    - Menos precisos que deep learning
    - Requieren buenas condiciones de iluminaci√≥n
    """)

with st.sidebar.expander("üé≠ Overlays y Efectos"):
    st.markdown("""
    **Tipos de Overlay:**
    - **üï∂Ô∏è Gafas de Sol**: Se colocan sobre los ojos
    - **ü•∏ Bigote**: Se posiciona bajo la nariz
    - **üé≠ M√°scara**: Cubre parcialmente el rostro
    
    **T√©cnica:**
    - Detecci√≥n de rostros primero
    - Redimensionamiento proporcional
    - Aplicaci√≥n con canal alpha (transparencia)
    - Posicionamiento relativo a la detecci√≥n
    """)

with st.sidebar.expander("‚öôÔ∏è Algoritmos Utilizados"):
    st.markdown("""
    **OpenCV Functions:**
    - `cv2.CascadeClassifier()`: Carga clasificador
    - `detectMultiScale()`: Detecci√≥n multi-escala
    - `cv2.rectangle()`: Dibujo de rect√°ngulos
    - `cv2.resize()`: Redimensionamiento
    - `cv2.cvtColor()`: Conversi√≥n de color
    
    **Flujo del Algoritmo:**
    1. Conversi√≥n a escala de grises
    2. B√∫squeda multi-escala de patrones
    3. Filtrado por vecinos m√≠nimos
    4. Eliminaci√≥n de duplicados
    5. Dibujo de resultados
    """)

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>üë§ <strong>Detecci√≥n Facial Interactiva</strong> | Cap√≠tulo 4 - Detecci√≥n de Caracter√≠sticas Faciales</p>
        <p><small>Explora diferentes t√©cnicas de detecci√≥n facial usando Haar Cascades</small></p>
    </div>
    """, 
    unsafe_allow_html=True
)